### Draft Specification: Suggested Formats for Inclusion in Duck Hunt v1.1.0

#### Overview
The following proposal outlines additional formats for inclusion in Duck Hunt v1.1.0. These formats focus on expanding support for logs and output relevant to **DevOps, security monitoring**, and infrastructure management use cases in addition to the current development-focused toolset. Each proposed addition addresses real-world needs in monitoring, compliance, and operational visibility.

---

### Proposed New Formats

#### **1. Apache HTTP Server Access Logs**
- **Use Case**: Monitoring web traffic, detecting anomalies, and analyzing HTTP request patterns.
- **Sample Format**:
  ```
  127.0.0.1 - - [12/Dec/2025:10:15:42 +0000] "GET /index.html HTTP/1.1" 200 1024
  ```
- **Proposed Format String**: `apache_access`
- **Use in Duck Hunt**:
  ```sql
  SELECT ip_address, request_method, status_code, response_size
  FROM read_duck_hunt_log('apache_access.log', 'apache_access')
  WHERE status_code != '200';
  ```

#### **2. NGINX Access Logs**
- **Use Case**: Similar to Apache logs, for monitoring traffic and load balancing analytics.
- **Sample Format**:
  ```
  192.168.1.10 - - [12/Dec/2025:12:34:56 +0000] "POST /api/v1/login HTTP/2.0" 401 512
  ```
- **Proposed Format String**: `nginx_access`
- **Use in Duck Hunt**:
  ```sql
  SELECT ip_address, request_path, status_code
  FROM read_duck_hunt_log('nginx_access.log', 'nginx_access')
  WHERE status_code >= '400';
  ```

#### **3. Syslog**
- **Use Case**: Capturing and analyzing system logs generated by various applications and services.
- **Sample Format**:
  ```
  Dec 12 10:15:42 localhost sshd[1234]: Accepted password for user from 10.0.0.1 port 22
  ```
- **Proposed Format String**: `syslog`
- **Use in Duck Hunt**:
  ```sql
  SELECT timestamp, service_name, message
  FROM read_duck_hunt_log('syslog', 'syslog')
  WHERE service_name = 'sshd';
  ```

#### **4. AWS CloudTrail Logs**
- **Use Case**: Monitoring AWS API calls for compliance and security event tracking.
- **Sample Format** (JSON):
  ```json
  {
    "eventTime": "2025-12-12T11:20:42Z",
    "eventName": "CreateUser",
    "awsRegion": "us-east-1",
    "sourceIPAddress": "192.168.1.100"
  }
  ```
- **Proposed Format String**: `aws_cloudtrail`
- **Use in Duck Hunt**:
  ```sql
  SELECT event_time, event_name, aws_region, source_ip_address
  FROM read_duck_hunt_log('cloudtrail.json', 'aws_cloudtrail')
  WHERE event_name = 'CreateUser';
  ```

#### **5. Kubernetes Application Logs**
- **Use Case**: Debugging and monitoring workloads running in Kubernetes clusters.
- **Sample Format**:
  ```
  {"level":"error","ts":"2025-12-12T15:30:00.123Z","msg":"Pod failed to start","namespace":"production","pod":"web-server"}
  ```
- **Proposed Format String**: `k8s_logs`
- **Use in Duck Hunt**:
  ```sql
  SELECT timestamp, severity, message, namespace, pod_name
  FROM read_duck_hunt_log('kubernetes.log', 'k8s_logs')
  WHERE severity = 'error';
  ```

#### **6. JSON Audit Logs**
- **Use Case**: Capturing audit trails for compliance across apps and infrastructures.
- **Sample Format (Generic JSON)**:
  ```json
  {
    "event_type": "LOGIN_ATTEMPT",
    "timestamp": "2025-12-12T18:45:00Z",
    "user": "admin",
    "status": "FAILURE"
  }
  ```
- **Proposed Format String**: `json_audit`
- **Use in Duck Hunt**:
  ```sql
  SELECT event_type, user, timestamp
  FROM read_duck_hunt_log('audit.json', 'json_audit')
  WHERE status = 'FAILURE';
  ```

#### **7. Firewall Logs (e.g., IPTables)**
- **Use Case**: Tracking network traffic and blocking unauthorized connections.
- **Sample Format**:
  ```
  Dec 12 10:15:42 firewall kernel: IN=eth0 OUT= MAC=00:00:5e:00:53:11 SRC=192.168.1.5 DST=192.168.1.1 LEN=60 TOS=0x00
  ```
- **Proposed Format String**: `firewall_logs`
- **Use in Duck Hunt**:
  ```sql
  SELECT timestamp, source_ip, destination_ip, message
  FROM read_duck_hunt_log('firewall.log', 'firewall_logs')
  WHERE source_ip LIKE '192.%';
  ```

---

### Summary

**Why These Formats?**
The selected formats provide a strong basis for extending Duck Hunt's capabilities beyond development outputs, helping DevOps and security teams monitor, debug, and secure production and staging environments.

**Implementation Priority:**
1. **Syslog**
2. **HTTP Logs** (`apache_access`, `nginx_access`)
3. **CloudTrail Logs**
4. **Firewall Logs**
5. **Kubernetes Logs**
6. **JSON Audit Logs**

Would you like me to expand on any of these formats or provide mock code for their integration?

Here are additional potential formats, beyond the 7 proposed earlier, that could be valuable for v1.1.0 in **DevOps** and **security monitoring** use cases:

### **Additional Format Suggestions**

#### **8. Windows Event Logs**
- **Use Case**: Capturing security, system, and application events on Windows servers or desktops.
- **Sample Format** (Exported as text or JSON):
  ```
  {
    "EventID": 4625,
    "Timestamp": "2025-12-12T10:00:00Z",
    "LogLevel": "Error",
    "Message": "Failed logon attempt."
  }
  ```
- **Proposed Format String**: `windows_event`
- **Use in Duck Hunt**:
  ```sql
  SELECT event_id, timestamp, log_level, message
  FROM read_duck_hunt_log('windows_event.json', 'windows_event')
  WHERE log_level = 'Error';
  ```

#### **9. SSH Logs**
- **Use Case**: Monitoring login attempts, including failed password attempts, for security threats.
- **Sample Format**:
  ```
  Dec 12 10:15:43 hostname sshd[1234]: Failed password for invalid user admin from 192.168.1.5 port 22
  ```
- **Proposed Format String**: `ssh_logs`
- **Use in Duck Hunt**:
  ```sql
  SELECT timestamp, user, ip_address, status
  FROM read_duck_hunt_log('auth.log', 'ssh_logs')
  WHERE status = 'Failed';
  ```

#### **10. Auditd Logs**
- **Use Case**: Capturing Linux system audit events (e.g., file access, program execution, user actions).
- **Sample Format**:
  ```
  type=SYSCALL msg=audit(1670846542.536): arch=c000003e syscall=59 success=yes
  ```
- **Proposed Format String**: `auditd_logs`
- **Use in Duck Hunt**:
  ```sql
  SELECT type, message, success
  FROM read_duck_hunt_log('auditd.log', 'auditd_logs')
  WHERE success = 'no';
  ```

#### **11. Firewall (Web Application Firewall or Proxy Logs)**
- **Use Case**: Monitoring and analyzing HTTP-based security threats like SQL injection or XSS attacks.
- **Sample Format**:
  ```
  192.168.1.5 - - [12/Dec/2025:17:00:00 +0000] "GET /index.php?id=1' OR 1 -- HTTP/1.1" 403
  ```
- **Proposed Format String**: `waf_logs`
- **Use in Duck Hunt**:
  ```sql
  SELECT ip_address, request_path, status_code, attack_vector
  FROM read_duck_hunt_log('waf.log', 'waf_logs')
  WHERE status_code != '200';
  ```

#### **12. AWS VPC Flow Logs**
- **Use Case**: Analyzing network connections, performance, or suspicious packet activity in AWS.
- **Sample Format**:
  ```
  02:31:22 accept 192.168.1.10 10.10.5.5 443 12345
  ```
- **Proposed Format String**: `vpc_flow`
- **Use in Duck Hunt**:
  ```sql
  SELECT timestamp, accept, source_ip, destination_port
  FROM read_duck_hunt_log('vpc_flow.log', 'vpc_flow')
  WHERE accept = 'deny';
  ```

#### **13. S3 Access Logs**
- **Use Case**: Monitoring data access in AWS S3 buckets for anomalous or unexpected activity.
- **Sample Format**:
  ```
  192.168.1.1 [12/Dec/2025:12:15:42 +0000] GET /mybucket/file.txt 200
  ```
- **Proposed Format String**: `s3_access`
- **Use in Duck Hunt**:
  ```sql
  SELECT source_ip, request_path, status_code
  FROM read_duck_hunt_log('s3_access.log', 's3_access')
  WHERE status_code != '200';
  ```

#### **14. GCP Logs**
- **Use Case**: Logging GCP service events, usage, and security-related actions.
- **Sample Format**:
  ```json
  {
    "protoPayload": {
      "methodName": "google.logging.v2.WriteLogEntries",
      "status": {"code": 500},
      "authenticationInfo": {"principalEmail": "user@example.com"}
    }
  }
  ```
- **Proposed Format String**: `gcp_logs`
- **Use in Duck Hunt**:
  ```sql
  SELECT method_name, principal_email, status_code
  FROM read_duck_hunt_log('gcp.json', 'gcp_logs')
  WHERE status_code >= 500;
  ```

#### **15. Azure Activity Logs**
- **Use Case**: Auditing user operations across Azure services for compliance and anomaly detection.
- **Sample Format**:
  ```json
  {
    "time": "2025-12-12T12:34:56+00:00",
    "operationName": "Create User",
    "status": "Succeeded",
    "callerIpAddress": "192.168.1.1"
  }
  ```
- **Proposed Format String**: `azure_activity`
- **Use in Duck Hunt**:
  ```sql
  SELECT time, operation_name, caller_ip_address, status
  FROM read_duck_hunt_log('azure.json', 'azure_activity')
  WHERE status != 'Succeeded';
  ```

---

### How These Formats Extend Use Cases
These additional formats largely target **cloud environments, infrastructure, and security monitoring**, filling gaps in current tools:
1. Cloud provider logs (AWS, GCP, Azure) provide rich insights into user and service-based actions.
2. SSH and Auditd logs help with threat detection for compromised systems.
3. WAF logs allow monitoring for HTTP application-level threats.

---

### Application Logging Libraries

These formats cover application-level logging from various programming languages and frameworks, enabling duck_hunt to parse runtime logs alongside build/test output.

#### **16. Python Logging (stdlib)**
- **Use Case**: Parsing logs from Python's built-in logging module.
- **Sample Format**:
  ```
  2025-01-15 10:30:45,123 - myapp.module - INFO - User login successful
  2025-01-15 10:30:46,456 - myapp.module - ERROR - Database connection failed
  ```
- **Proposed Format String**: `python_logging`
- **Use in Duck Hunt**:
  ```sql
  SELECT timestamp, logger_name, severity, message
  FROM read_duck_hunt_log('app.log', 'python_logging')
  WHERE severity = 'ERROR';
  ```

#### **17. Structlog (Python)**
- **Use Case**: Structured logging for Python applications outputting JSON.
- **Sample Format**:
  ```json
  {"event": "user_login", "user_id": 123, "level": "info", "timestamp": "2025-01-15T10:30:45Z"}
  ```
- **Proposed Format String**: `structlog_json`
- **Use in Duck Hunt**:
  ```sql
  SELECT event, level, timestamp
  FROM read_duck_hunt_log('app.log', 'structlog_json')
  WHERE level = 'error';
  ```

#### **18. Loguru (Python)**
- **Use Case**: Popular Python logging alternative with distinctive colored output.
- **Sample Format**:
  ```
  2025-01-15 10:30:45.123 | INFO     | myapp.module:function:42 - Processing request
  2025-01-15 10:30:46.456 | ERROR    | myapp.module:function:55 - Request failed
  ```
- **Proposed Format String**: `loguru_text`
- **Use in Duck Hunt**:
  ```sql
  SELECT timestamp, severity, module, function_name, line_number, message
  FROM read_duck_hunt_log('app.log', 'loguru_text')
  WHERE severity = 'ERROR';
  ```

#### **19. Winston (Node.js)**
- **Use Case**: Most popular Node.js logging library.
- **Sample Format (JSON)**:
  ```json
  {"level":"error","message":"Connection timeout","service":"api","timestamp":"2025-01-15T10:30:45.123Z"}
  ```
- **Sample Format (Text)**:
  ```
  2025-01-15T10:30:45.123Z [api] error: Connection timeout
  ```
- **Proposed Format Strings**: `winston_json`, `winston_text`
- **Use in Duck Hunt**:
  ```sql
  SELECT level, service, message, timestamp
  FROM read_duck_hunt_log('app.log', 'winston_json')
  WHERE level = 'error';
  ```

#### **20. Pino (Node.js)**
- **Use Case**: Fast JSON logger for Node.js, commonly used in production.
- **Sample Format**:
  ```json
  {"level":30,"time":1705315845123,"pid":1234,"hostname":"server1","msg":"request completed"}
  {"level":50,"time":1705315846456,"pid":1234,"hostname":"server1","msg":"database error","err":{"message":"timeout"}}
  ```
- **Proposed Format String**: `pino_json`
- **Use in Duck Hunt**:
  ```sql
  SELECT level, hostname, msg, time
  FROM read_duck_hunt_log('app.log', 'pino_json')
  WHERE level >= 50;
  ```

#### **21. Bunyan (Node.js)**
- **Use Case**: JSON logging library for Node.js with structured output.
- **Sample Format**:
  ```json
  {"name":"myapp","hostname":"server1","pid":1234,"level":30,"msg":"listening on port 3000","time":"2025-01-15T10:30:45.123Z","v":0}
  ```
- **Proposed Format String**: `bunyan_json`
- **Use in Duck Hunt**:
  ```sql
  SELECT name, level, msg, time
  FROM read_duck_hunt_log('app.log', 'bunyan_json')
  WHERE level >= 40;
  ```

#### **22. Log4j / Logback (Java)**
- **Use Case**: Extremely common Java logging frameworks.
- **Sample Format**:
  ```
  2025-01-15 10:30:45,123 INFO  [main] com.example.App - Application started
  2025-01-15 10:30:46,456 ERROR [http-thread-1] com.example.Service - NullPointerException
  ```
- **Proposed Format String**: `log4j_text`
- **Use in Duck Hunt**:
  ```sql
  SELECT timestamp, severity, thread, class_name, message
  FROM read_duck_hunt_log('app.log', 'log4j_text')
  WHERE severity = 'ERROR';
  ```

#### **23. Java Stack Traces**
- **Use Case**: Parsing multiline Java exception stack traces.
- **Sample Format**:
  ```
  java.lang.NullPointerException: Cannot invoke method on null
      at com.example.Service.process(Service.java:42)
      at com.example.Controller.handle(Controller.java:15)
      at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
  Caused by: java.io.IOException: Connection reset
      at java.net.SocketInputStream.read(SocketInputStream.java:210)
  ```
- **Proposed Format String**: `java_stacktrace`
- **Use in Duck Hunt**:
  ```sql
  SELECT exception_type, message, file_path, line_number, caused_by
  FROM read_duck_hunt_log('error.log', 'java_stacktrace');
  ```

#### **24. Zap (Go)**
- **Use Case**: Uber's high-performance structured logger for Go.
- **Sample Format**:
  ```json
  {"level":"info","ts":1705315845.123,"caller":"server/main.go:42","msg":"server starting","port":8080}
  {"level":"error","ts":1705315846.456,"caller":"db/conn.go:55","msg":"connection failed","error":"timeout"}
  ```
- **Proposed Format String**: `zap_json`
- **Use in Duck Hunt**:
  ```sql
  SELECT level, caller, msg, ts
  FROM read_duck_hunt_log('app.log', 'zap_json')
  WHERE level = 'error';
  ```

#### **25. Logrus (Go)**
- **Use Case**: Popular structured logger for Go applications.
- **Sample Format (JSON)**:
  ```json
  {"level":"info","msg":"server started","port":8080,"time":"2025-01-15T10:30:45Z"}
  ```
- **Sample Format (Text)**:
  ```
  time="2025-01-15T10:30:45Z" level=info msg="server started" port=8080
  ```
- **Proposed Format Strings**: `logrus_json`, `logrus_text`
- **Use in Duck Hunt**:
  ```sql
  SELECT level, msg, time
  FROM read_duck_hunt_log('app.log', 'logrus_json')
  WHERE level = 'error';
  ```

#### **26. Zerolog (Go)**
- **Use Case**: Zero-allocation JSON logger for Go.
- **Sample Format**:
  ```json
  {"level":"info","time":"2025-01-15T10:30:45Z","message":"request processed","duration_ms":45}
  ```
- **Proposed Format String**: `zerolog_json`
- **Use in Duck Hunt**:
  ```sql
  SELECT level, message, time, duration_ms
  FROM read_duck_hunt_log('app.log', 'zerolog_json')
  WHERE level = 'error';
  ```

#### **27. Ruby Logger (stdlib)**
- **Use Case**: Ruby's built-in Logger class output.
- **Sample Format**:
  ```
  I, [2025-01-15T10:30:45.123456 #1234]  INFO -- myapp: User logged in
  E, [2025-01-15T10:30:46.456789 #1234] ERROR -- myapp: Connection failed
  ```
- **Proposed Format String**: `ruby_logger`
- **Use in Duck Hunt**:
  ```sql
  SELECT severity, timestamp, program, message
  FROM read_duck_hunt_log('app.log', 'ruby_logger')
  WHERE severity = 'ERROR';
  ```

#### **28. Rails Application Logs**
- **Use Case**: Ruby on Rails application and request logs.
- **Sample Format**:
  ```
  Started GET "/users" for 127.0.0.1 at 2025-01-15 10:30:45 +0000
  Processing by UsersController#index as HTML
  Completed 200 OK in 45ms (Views: 30.2ms | ActiveRecord: 12.1ms)
  ```
- **Proposed Format String**: `rails_log`
- **Use in Duck Hunt**:
  ```sql
  SELECT request_method, path, controller, action, status_code, duration_ms
  FROM read_duck_hunt_log('production.log', 'rails_log')
  WHERE status_code >= 400;
  ```

#### **29. R Logger**
- **Use Case**: R's logger package output.
- **Sample Format**:
  ```
  INFO [2025-01-15 10:30:45] Processing dataset
  ERROR [2025-01-15 10:30:46] Failed to load file: data.csv
  ```
- **Proposed Format String**: `r_logger`
- **Use in Duck Hunt**:
  ```sql
  SELECT severity, timestamp, message
  FROM read_duck_hunt_log('analysis.log', 'r_logger')
  WHERE severity = 'ERROR';
  ```

#### **30. Futile.logger (R)**
- **Use Case**: Popular R logging package with hierarchical loggers.
- **Sample Format**:
  ```
  INFO [2025-01-15 10:30:45] mypackage.module - Analysis complete
  ERROR [2025-01-15 10:30:46] mypackage.io - File not found
  ```
- **Proposed Format String**: `r_futile_logger`
- **Use in Duck Hunt**:
  ```sql
  SELECT severity, timestamp, logger, message
  FROM read_duck_hunt_log('analysis.log', 'r_futile_logger')
  WHERE severity = 'ERROR';
  ```

#### **31. Serilog (.NET)**
- **Use Case**: Popular structured logging for .NET applications.
- **Sample Format (JSON)**:
  ```json
  {"@t":"2025-01-15T10:30:45.123Z","@mt":"User {UserId} logged in","UserId":123,"@l":"Information"}
  ```
- **Sample Format (Text)**:
  ```
  [10:30:45 INF] User 123 logged in
  [10:30:46 ERR] Database connection failed
  ```
- **Proposed Format Strings**: `serilog_json`, `serilog_text`
- **Use in Duck Hunt**:
  ```sql
  SELECT level, message_template, timestamp
  FROM read_duck_hunt_log('app.log', 'serilog_json')
  WHERE level = 'Error';
  ```

#### **32. NLog (.NET)**
- **Use Case**: Flexible logging for .NET applications.
- **Sample Format**:
  ```
  2025-01-15 10:30:45.1234|INFO|MyApp.Program|Application started
  2025-01-15 10:30:46.5678|ERROR|MyApp.Service|Connection failed|System.TimeoutException
  ```
- **Proposed Format String**: `nlog_text`
- **Use in Duck Hunt**:
  ```sql
  SELECT timestamp, severity, logger, message, exception_type
  FROM read_duck_hunt_log('app.log', 'nlog_text')
  WHERE severity = 'ERROR';
  ```

---

### Cross-Language Structured Formats

These formats are used across multiple languages and ecosystems for structured logging.

#### **33. JSON Lines (JSONL/NDJSON)**
- **Use Case**: One JSON object per line - extremely common for structured logs.
- **Sample Format**:
  ```
  {"timestamp":"2025-01-15T10:30:45Z","level":"info","message":"Request received","request_id":"abc123"}
  {"timestamp":"2025-01-15T10:30:46Z","level":"error","message":"Request failed","request_id":"abc123","error":"timeout"}
  ```
- **Proposed Format String**: `jsonl`
- **Use in Duck Hunt**:
  ```sql
  SELECT level, message, request_id, timestamp
  FROM read_duck_hunt_log('app.log', 'jsonl')
  WHERE level = 'error';
  ```

#### **34. Logfmt**
- **Use Case**: Key=value pairs, popular in Go ecosystem and Heroku.
- **Sample Format**:
  ```
  level=info ts=2025-01-15T10:30:45Z msg="request completed" method=GET path=/api/users status=200 duration=45ms
  level=error ts=2025-01-15T10:30:46Z msg="database error" err="connection timeout"
  ```
- **Proposed Format String**: `logfmt`
- **Use in Duck Hunt**:
  ```sql
  SELECT level, msg, method, path, status, duration
  FROM read_duck_hunt_log('app.log', 'logfmt')
  WHERE level = 'error';
  ```

#### **35. GELF (Graylog Extended Log Format)**
- **Use Case**: Structured logging format designed for Graylog but widely adopted.
- **Sample Format**:
  ```json
  {"version":"1.1","host":"server1","short_message":"Request failed","level":3,"timestamp":1705315845.123,"_request_id":"abc123"}
  ```
- **Proposed Format String**: `gelf`
- **Use in Duck Hunt**:
  ```sql
  SELECT host, short_message, level, timestamp
  FROM read_duck_hunt_log('app.log', 'gelf')
  WHERE level <= 3;
  ```

#### **36. CEF (Common Event Format)**
- **Use Case**: Security logging standard used by SIEM tools.
- **Sample Format**:
  ```
  CEF:0|Security|ThreatManager|1.0|100|Malware detected|10|src=192.168.1.5 dst=10.0.0.1 spt=1234
  ```
- **Proposed Format String**: `cef`
- **Use in Duck Hunt**:
  ```sql
  SELECT vendor, product, event_name, severity, src_ip, dst_ip
  FROM read_duck_hunt_log('security.log', 'cef')
  WHERE severity >= 7;
  ```

---

### Log Aggregator Formats

These formats are specific to popular log aggregation and analysis platforms.

#### **37. Splunk JSON**
- **Use Case**: Logs formatted for Splunk ingestion.
- **Sample Format**:
  ```json
  {"time":1705315845,"event":{"level":"error","message":"Connection failed"},"source":"myapp","sourcetype":"application"}
  ```
- **Proposed Format String**: `splunk_json`
- **Use in Duck Hunt**:
  ```sql
  SELECT source, sourcetype, event_level, event_message, time
  FROM read_duck_hunt_log('splunk.log', 'splunk_json')
  WHERE event_level = 'error';
  ```

#### **38. Datadog JSON**
- **Use Case**: Logs formatted for Datadog ingestion.
- **Sample Format**:
  ```json
  {"message":"Request processed","status":"info","service":"api","ddsource":"nodejs","ddtags":"env:prod,version:1.2.3"}
  ```
- **Proposed Format String**: `datadog_json`
- **Use in Duck Hunt**:
  ```sql
  SELECT service, status, message, ddsource, ddtags
  FROM read_duck_hunt_log('datadog.log', 'datadog_json')
  WHERE status = 'error';
  ```

#### **39. Fluentd/Fluent Bit**
- **Use Case**: Logs from Fluentd/Fluent Bit log processors.
- **Sample Format**:
  ```json
  {"time":"2025-01-15T10:30:45+00:00","tag":"app.backend","record":{"level":"error","message":"timeout"}}
  ```
- **Proposed Format String**: `fluentd_json`
- **Use in Duck Hunt**:
  ```sql
  SELECT tag, record_level, record_message, time
  FROM read_duck_hunt_log('fluent.log', 'fluentd_json')
  WHERE record_level = 'error';
  ```

---

### Summary of Application Logging Formats

| Language/Platform | Format Strings | Priority |
|-------------------|----------------|----------|
| Python | `python_logging`, `structlog_json`, `loguru_text` | High |
| Node.js | `winston_json`, `winston_text`, `pino_json`, `bunyan_json` | High |
| Java/JVM | `log4j_text`, `java_stacktrace` | High |
| Go | `zap_json`, `logrus_json`, `logrus_text`, `zerolog_json` | Medium |
| Ruby | `ruby_logger`, `rails_log` | Medium |
| R | `r_logger`, `r_futile_logger` | Low |
| .NET | `serilog_json`, `serilog_text`, `nlog_text` | Medium |
| Cross-language | `jsonl`, `logfmt`, `gelf`, `cef` | High |
| Aggregators | `splunk_json`, `datadog_json`, `fluentd_json` | Medium |

**Implementation Priority:**
1. `jsonl` / `logfmt` - Universal structured formats
2. `python_logging`, `loguru_text` - Python ecosystem
3. `winston_json`, `pino_json` - Node.js ecosystem
4. `log4j_text`, `java_stacktrace` - Java ecosystem
5. `zap_json`, `logrus_json` - Go ecosystem
6. Platform-specific formats (Ruby, R, .NET)

---

## Schema Review Notes

### Incomplete/Odd Field Mappings (TODO)

The current ValidationEvent schema was designed for test results and lint output. As we add web access logs, system logs, and cloud provider logs, some field mappings are awkward:

**Phase 3C Workflow Fields Not Exposed:**
- `started_at`, `completed_at` - exist in ValidationEvent but not in table function output schema
- `workflow_name`, `job_name`, `step_name` - workflow hierarchy fields not exposed
- These would be useful for timestamps in access/system logs

**Current Workarounds:**
| Log Field | Using Column | Should Be |
|-----------|--------------|-----------|
| Timestamp (access logs) | `function_name` | `started_at` or new `timestamp` |
| IP address | `structured_data` JSON | Could be dedicated column |
| HTTP status code | `error_code` | Reasonable fit |
| Response bytes | `structured_data` JSON | Could be dedicated column |
| Hostname (syslog) | `structured_data` JSON | Could be dedicated column |
| PID (syslog) | `structured_data` JSON | Reasonable |

**Proposed Schema Additions (after cloud formats implemented):**
- `started_at` (VARCHAR) - Event timestamp in ISO format
- `ip_address` (VARCHAR) - Source IP for access/security logs
- `hostname` (VARCHAR) - Source hostname for system logs
- `http_status` (INTEGER) - HTTP status code for access logs
- `response_bytes` (BIGINT) - Response size for access logs
- `principal` (VARCHAR) - User/service identity for cloud audit logs
- `cloud_region` (VARCHAR) - AWS/GCP/Azure region

**Action:** Review schema after implementing CloudTrail, GCP, and Azure log formats to determine which columns are truly needed across multiple format types.
