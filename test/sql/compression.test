# name: test/sql/compression.test
# description: Test transparent compression support for read_duck_hunt_log and read_duck_hunt_workflow_log
# group: [sql]

require duck_hunt

# =============================================================================
# GZIP Compression Tests for read_duck_hunt_log
# =============================================================================

# Test 1: Basic GZIP reading with explicit format
query III
SELECT tool_name, COUNT(*) as events, COUNT(CASE WHEN status = 'FAIL' THEN 1 END) as failures
FROM read_duck_hunt_log('test/samples/pytest.json.gz', 'pytest_json')
GROUP BY tool_name;
----
pytest	4	1

# Test 2: Verify compressed file produces identical results to uncompressed
query I
SELECT COUNT(*) FROM (
  SELECT event_id, tool_name, status, test_name, message
  FROM read_duck_hunt_log('test/samples/pytest.json', 'pytest_json')
  EXCEPT
  SELECT event_id, tool_name, status, test_name, message
  FROM read_duck_hunt_log('test/samples/pytest.json.gz', 'pytest_json')
);
----
0

# Test 3: GZIP with auto-detection format
query II
SELECT tool_name, COUNT(*) as events
FROM read_duck_hunt_log('test/samples/pytest.json.gz', 'auto')
GROUP BY tool_name;
----
pytest	4

# Test 4: GZIP with ESLint JSON format
query III
SELECT tool_name,
       COUNT(CASE WHEN status = 'ERROR' THEN 1 END) as errors,
       COUNT(CASE WHEN status = 'WARNING' THEN 1 END) as warnings
FROM read_duck_hunt_log('test/samples/eslint.json.gz', 'eslint_json')
WHERE event_type != 'summary'
GROUP BY tool_name;
----
eslint	1	2

# Test 5: Verify ESLint compressed matches uncompressed
query I
SELECT COUNT(*) FROM (
  SELECT event_id, ref_file, ref_line, status, message
  FROM read_duck_hunt_log('test/samples/eslint.json', 'eslint_json')
  EXCEPT
  SELECT event_id, ref_file, ref_line, status, message
  FROM read_duck_hunt_log('test/samples/eslint.json.gz', 'eslint_json')
);
----
0

# Test 6: All schema fields are preserved through compression
query I
SELECT COUNT(*) FROM (
  SELECT event_id, tool_name, event_type, ref_file, ref_line, ref_column,
         function_name, status, severity, category, message, suggestion,
         error_code, test_name, execution_time, log_content, structured_data
  FROM read_duck_hunt_log('test/samples/pytest.json.gz', 'pytest_json')
  WHERE event_id IS NOT NULL AND tool_name IS NOT NULL
);
----
4

# =============================================================================
# GZIP Compression Tests for read_duck_hunt_workflow_log
# =============================================================================

# Test 7: Basic workflow log GZIP reading
# Note: GitHub Actions parser now emits meaningful events only (not all lines)
query II
SELECT tool_name, COUNT(*) as events
FROM read_duck_hunt_workflow_log('test/samples/github_actions.log.gz', 'github_actions')
GROUP BY tool_name;
----
github_actions	9

# Test 8: Verify workflow compressed matches uncompressed
query I
SELECT COUNT(*) FROM (
  SELECT event_id, scope, "group", unit, unit_status, message
  FROM read_duck_hunt_workflow_log('test/samples/github_actions.log', 'github_actions')
  EXCEPT
  SELECT event_id, scope, "group", unit, unit_status, message
  FROM read_duck_hunt_workflow_log('test/samples/github_actions.log.gz', 'github_actions')
);
----
0

# Test 9: Workflow log with auto-detection on compressed file
query II
SELECT tool_name, COUNT(*) as events
FROM read_duck_hunt_workflow_log('test/samples/github_actions.log.gz', 'auto')
GROUP BY tool_name;
----
github_actions	9

# =============================================================================
# Severity Threshold with Compression
# =============================================================================

# Test 10: Severity filtering works with compressed files
query II
SELECT status, COUNT(*) as count
FROM read_duck_hunt_log('test/samples/pytest.json.gz', 'pytest_json', severity_threshold := 'error')
GROUP BY status
ORDER BY status;
----
ERROR	1
FAIL	1

# =============================================================================
# Edge Cases
# =============================================================================

# Test 11: Event ordering is preserved through compression
query II
SELECT event_id, status
FROM read_duck_hunt_log('test/samples/pytest.json.gz', 'pytest_json')
ORDER BY event_id;
----
1	PASS
2	FAIL
3	PASS
4	ERROR

# Test 12: Compressed file with multiple record types (ESLint has errors and warnings)
query III
SELECT status, severity, COUNT(*) as count
FROM read_duck_hunt_log('test/samples/eslint.json.gz', 'eslint_json')
WHERE event_type != 'summary'
GROUP BY status, severity
ORDER BY status, severity;
----
ERROR	error	1
WARNING	warning	2

# Test 13: log_file field correctly shows .gz extension
query I
SELECT DISTINCT log_file LIKE '%.gz' as has_gz_extension
FROM read_duck_hunt_log('test/samples/pytest.json.gz', 'pytest_json');
----
true
